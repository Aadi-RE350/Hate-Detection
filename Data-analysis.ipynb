{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f3c0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in successfully.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"TOKEN\")\n",
    "\n",
    "if not token:\n",
    "    raise ValueError(\"Token not found in .env\")\n",
    "\n",
    "login(token=token, add_to_git_credential=True)\n",
    "print(\"Logged in successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11727083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Parquet saved at Data/available_metahate.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/irlab-udc/metahate/available_metahate.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Save as fast Parquet file\n",
    "df.to_parquet(\"Data/available_metahate.parquet\")\n",
    "\n",
    "print(\"Done. Parquet saved at Data/available_metahate.parquet\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1083f0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32863c16f0b54f178f117835d37d08a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 1101165\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files=\"Data/available_metahate.parquet\"\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd8226",
   "metadata": {},
   "source": [
    "1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77fd94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1101165\n",
      "Features: {'label': Value('int64'), 'text': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "ds = dataset[\"train\"]\n",
    "print(\"Rows:\", len(ds))\n",
    "print(\"Features:\", ds.features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d65c0",
   "metadata": {},
   "source": [
    "2. Missing value analysis (text-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a50dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label    0\n",
      "text     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = ds.to_pandas()\n",
    "\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29404e9",
   "metadata": {},
   "source": [
    "3. Label distribution (numbers + percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab544d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      " label\n",
      "0    867876\n",
      "1    233289\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage (%):\n",
      " label\n",
      "0    78.81\n",
      "1    21.19\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "counts = df['label'].value_counts()\n",
    "percent = df['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Counts:\\n\", counts)\n",
    "print(\"\\nPercentage (%):\\n\", percent.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e411c",
   "metadata": {},
   "source": [
    "4. Text Length Analysis (summary stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ab0eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.101164e+06\n",
      "mean     2.738461e+02\n",
      "std      5.131642e+02\n",
      "min      1.000000e+00\n",
      "25%      7.500000e+01\n",
      "50%      1.340000e+02\n",
      "75%      2.710000e+02\n",
      "max      2.003000e+04\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df[\"text_length\"] = df[\"text\"].str.len()\n",
    "print(df[\"text_length\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c5ac3",
   "metadata": {},
   "source": [
    "5. Common words (text-only frequency list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a211a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 93805), ('to', 58366), ('i', 48886), ('a', 46947), ('and', 45362), ('of', 43056), ('you', 42888), ('is', 35536), ('that', 31614), ('it', 29818), ('in', 29072), ('for', 20189), ('this', 18816), ('t', 18218), ('not', 17706), ('on', 17379), ('s', 16666), ('be', 16312), ('are', 15678), ('as', 14113), ('have', 13788), ('your', 12678), ('with', 12434), ('if', 11057), ('was', 10765), ('but', 10548), ('or', 10012), ('my', 9388), ('article', 8964), ('an', 8669), ('they', 8230), ('so', 7950), ('can', 7939), ('do', 7874), ('from', 7796), ('by', 7762), ('me', 7760), ('at', 7730), ('what', 7582), ('like', 7456), ('all', 7455), ('about', 7448), ('he', 7187), ('wikipedia', 7082), ('user', 6774), ('there', 6772), ('page', 6668), ('just', 6610), ('will', 6516), ('no', 6202)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "# sample 50k rows for speed\n",
    "for text in df['text'].sample(50000, random_state=42):\n",
    "    counter.update(tokenize(text))\n",
    "\n",
    "print(counter.most_common(50))  # top 50 words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c435d3e",
   "metadata": {},
   "source": [
    "6. Compare words used in hate vs non-hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "067c1a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top hate words: [('you', 48507), ('the', 45339), ('a', 39708), ('i', 39045), ('to', 32943), ('and', 30072), ('is', 24364), ('of', 22539), ('that', 17330), ('it', 16083), ('are', 15965), ('t', 15298), ('in', 14713), ('fuck', 12006), ('your', 11824), ('s', 11510), ('this', 11288), ('for', 10736), ('not', 9911), ('on', 8856), ('my', 8676), ('with', 8523), ('be', 8311), ('have', 8231), ('they', 8077), ('me', 7665), ('nigger', 7579), ('like', 7557), ('user', 7543), ('fucking', 7084)]\n",
      "\n",
      "Top non-hate words: [('the', 110572), ('to', 66529), ('i', 53351), ('and', 50306), ('a', 49605), ('of', 49531), ('you', 42876), ('is', 39245), ('that', 36199), ('it', 33870), ('in', 33282), ('for', 23501), ('this', 21353), ('not', 20453), ('on', 19958), ('be', 18837), ('t', 18805), ('s', 18291), ('as', 16705), ('are', 16364), ('have', 15959), ('with', 13689), ('if', 12862), ('was', 12519), ('your', 12229), ('but', 12099), ('or', 11684), ('article', 10844), ('my', 10359), ('an', 9209)]\n"
     ]
    }
   ],
   "source": [
    "hate_df = df[df['label'] == 1][\"text\"]\n",
    "nonhate_df = df[df['label'] == 0][\"text\"]\n",
    "\n",
    "def build_counter(text_series):\n",
    "    c = Counter()\n",
    "    for t in text_series.sample(min(50000, len(text_series)), random_state=42):\n",
    "        c.update(tokenize(t))\n",
    "    return c\n",
    "\n",
    "hate_words = build_counter(hate_df)\n",
    "nonhate_words = build_counter(nonhate_df)\n",
    "\n",
    "print(\"Top hate words:\", hate_words.most_common(30))\n",
    "print(\"\\nTop non-hate words:\", nonhate_words.most_common(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53907243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0, 0, 0, 0, 0],\n",
       " 'text': [\"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\",\n",
       "  '!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!',\n",
       "  '!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit',\n",
       "  '!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny',\n",
       "  '!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
